{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fb18bf",
   "metadata": {},
   "source": [
    "# Proyecto Parcial 2 - Transformers\n",
    "\n",
    "Raúl Reyes Urbina\n",
    "\n",
    "---\n",
    "\n",
    "## Que son los Transormers? \n",
    "\n",
    "Los transformers son un tipo de arquitectura de red neuronal que transforma o cambia una secuencia de entrada en una secuencia de salida. Para ello, aprenden el contexto y rastrean las relaciones entre los componentes de la secuencia.\n",
    "\n",
    "---\n",
    "\n",
    "### Componentes Principales\n",
    "\n",
    "#### 1. Encoder (Codificador)\n",
    "- Procesa la secuencia de entrada.\n",
    "- Consta de varias capas idénticas.\n",
    "- Cada capa incluye:\n",
    "  - Multi-Head Self-Attention\n",
    "  - Feed-Forward Network (FFN)\n",
    "  - Normalización y conexiones residuales\n",
    "\n",
    "#### 2. Decoder (Decodificador)\n",
    "- Genera la secuencia de salida.\n",
    "- También tiene varias capas, con componentes adicionales:\n",
    "  - Masked Multi-Head Self-Attention (para evitar ver el futuro)\n",
    "  - Multi-Head Attention sobre la salida del encoder\n",
    "  - Feed-Forward Network y normalización\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Mecanismo de Self-Attention\n",
    "\n",
    "Permite al modelo enfocarse en diferentes partes de la secuencia al procesar cada palabra.\n",
    "\n",
    "Fórmula base:\n",
    "$$\n",
    "Attention(Q, K, V) = softmax(QKᵀ / √d_k) * V\n",
    "$$\n",
    "\n",
    "- Q = Query\n",
    "- K = Key\n",
    "- V = Value\n",
    "- d_k = dimensión del key\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Multi-Head Attention\n",
    "\n",
    "- Se ejecuta la atención varias veces en paralelo (varias \"cabezas\").\n",
    "- Cada cabeza aprende diferentes patrones/contextos.\n",
    "- Las salidas se concatenan y proyectan.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Feed-Forward Networks\n",
    "\n",
    "- Red neuronal densa aplicada por token:\n",
    "$$\n",
    "FFN(x) = max(0, xW₁ + b₁)W₂ + b₂\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Positional Encoding\n",
    "\n",
    "- Como no hay recurrencia, se agregan codificaciones posicionales al embedding de cada token.\n",
    "- Ejemplo con senos y cosenos:\n",
    "$$\n",
    "PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
    "PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Otras características\n",
    "\n",
    "- **Residual connections**: ayudan a evitar el desvanecimiento del gradiente.\n",
    "- **Layer Normalization**: estabiliza el entrenamiento.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- Captura relaciones a largo plazo sin recurrencia.\n",
    "- Altamente paralelizable → más rápido en entrenamiento.\n",
    "- Base de modelos como BERT, GPT, T5, RoBERTa, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Aplicaciones en PLN\n",
    "\n",
    "- Traducción automática\n",
    "- Resumen de texto\n",
    "- Generación de texto\n",
    "- Chatbots\n",
    "- Análisis de sentimientos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b3c9a",
   "metadata": {},
   "source": [
    "## Generacion de resumenes usando transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b1135",
   "metadata": {},
   "source": [
    "Instalamos las bilbioteca necesaria para usar transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af74bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch\n",
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c4052",
   "metadata": {},
   "source": [
    "Importamos las dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c805cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline # La usamos para el manejo de los transofrmers\n",
    "from IPython.display import display, HTML # Para mostrar el texto con saltos de linea\n",
    "import sys # Para leer los archivos txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f858416",
   "metadata": {},
   "source": [
    "Generamos funcion para cargar texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9c57c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_texto(ruta_archivo):\n",
    "    with open(ruta_archivo, 'r', encoding='utf-8') as archivo:\n",
    "        return archivo.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a0af9",
   "metadata": {},
   "source": [
    "Esta funcion nos facilita la impresion de texto largo, en donde automaticamente usando etiquetas y estilos HTML/CSS se hace wrap y se muestra de manera ordenada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0e4006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_texto(texto):\n",
    "    display(HTML(f\"<div style='white-space: pre-wrap; font-family: monospace'>{texto}</div>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dce5a2a",
   "metadata": {},
   "source": [
    "Con la siguiente funcion generaremos los resumenes, a esta se le apsa como parametro el texto a resumir, establecemos un par de variables para definir el tamaño maximo de los chunks y el modelo a usar, en este caso usando Bart el tamaño de chunk maximo recomendado son 1000 caracteres, por lo que lo establecemos como max_chunk, posteriormente generamos un pipeline para resumenes usando el modelo definido, y partimos el texto en partes del tamaño de los chunks, iteramos sobre estos chunks usando el pipeline para ir resumiendo cada uno y juntarlos en un array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83524056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumir_texto(texto):\n",
    "    max_chunk = 1000\n",
    "    modelo=\"facebook/bart-large-cnn\"\n",
    "    resumen_pipeline = pipeline(\"summarization\", model=modelo)\n",
    "    partes = [texto[i:i+max_chunk] for i in range(0, len(texto), max_chunk)]\n",
    "\n",
    "    resumenes = []\n",
    "\n",
    "    for i, parte in enumerate(partes):\n",
    "        print(f\"Resumiendo parte {i+1}/{len(partes)}...\")\n",
    "        resumen = resumen_pipeline(parte, max_length=130, min_length=30, do_sample=False)\n",
    "        resumenes.append(resumen[0]['summary_text'])\n",
    "    \n",
    "    resumen_final = \" \".join(resumenes)\n",
    "    return resumen_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04915245",
   "metadata": {},
   "source": [
    "Finalmente llamamos las funciones e imprimimos texto orignal y texto resumido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f4e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; font-family: monospace'>\n",
       "Texto original:</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; font-family: monospace'>El matemático inglés Alan Turing fue uno de los pioneros más importantes en el delineamiento de lo que más tarde se convertiría en la teoría de la computación. El misterio fue un común denominador a lo largo de su vida, entre otras cosas por su participación en el servicio británico de inteligencia durante la Segunda Guerra Mundial y por sus mal vistas inclinaciones sexuales. Su vida, llena de soledad y tropiezos, fue duramente juzgada al exponer públicamente su homosexualidad en los años cincue...\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumiendo parte 1/13...\n",
      "Resumiendo parte 2/13...\n",
      "Resumiendo parte 3/13...\n",
      "Resumiendo parte 4/13...\n",
      "Resumiendo parte 5/13...\n",
      "Resumiendo parte 6/13...\n",
      "Resumiendo parte 7/13...\n",
      "Resumiendo parte 8/13...\n",
      "Resumiendo parte 9/13...\n",
      "Resumiendo parte 10/13...\n",
      "Resumiendo parte 11/13...\n",
      "Resumiendo parte 12/13...\n",
      "Resumiendo parte 13/13...\n",
      "Resumen:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='white-space: pre-wrap; font-family: monospace'>El matemático inglés Alan Turing fue uno of los pioneros más importantes en el delineamiento de lo que más tarde se convertiría en la teoría of la computación. Su vida, llena of soledad y tropiezos, fue duramente juzgada al exponer públicamente su homosexualidad. Alan Turing fue el segundo y Último hijo de Julius Turing y Ethel Sara Stone. Turing lo colocaba en el árbol genealógico de una familia que, aunque no era rica, pertenecía a la clase. Alan Turing nació en Warrington Lodge, en Londres, Inglaterra, el 23 de junio de 1912. Su padre ingresó al servicio civil de la India. Ethel era la hija del ingeniero en jefe de los ferrocarriles de Madras. Alan se interesó en química cuando contaba ocho años de edad. En 1922 ingresó a la escuela preparatoria Hazlehurst, donde estudiaba su hermano. Alan se enseñó a sí mismo. Aprobó el examen común de admisión a escuelas públicas en 1925. Fue en esta época también en la que empezó a desarrollar una afición hacia el atletis. Pese a su mal desempeño en materias no relacionadas with las ciencias, Turing logró sobrevivir en Sherborne. En 1928 se interesó en la teoría general de la relatividad, de Albert Einstein. Turing conoció al joven Christopher Morcom, un estudiante muy brillante. Morcón provenía de una familia rica with fuertes bases científicas and artísticas. Turing se sintió inmediatamente atraído por el enorme talento y las sagaz inteligencia. Christopher Morcom murió el 13 de febrero de 1930, después oficialmente oficializado. Alan Turing tuvo la osadía de imitar a Morcom, a pesar de contar con solo 17 años de edad. Morcom poseía aptitudes que estaban mucho más allá de la capacidad de Turing. Alan Turing atribuyó su muerte a un envenenamiento. Morcom había contraído tuberculosis bovina en la infancia. Su mal se agudizó tras una operación que se efectuó en 1927. En 1932 Alan Turing comenzó a estudiar el entonces reciente trabajo de von Newman en mecánica cuántica. En esa época hizo amistad con un joven estudiante de matemáticas llamado James Atkins. Al mismo tiempo, el ambiente más relajado que en Sherborne le hizo sentirse. Turing se unió al movimiento antibélico que pululaba en el Cambridge. Su redescubrimiento del teorema del límite central le hizo acreedor a una beca Harold Fry del King's College. Turing demostró sorpresivamente que realmente, ‘no’ no existe un método definido that pueda ser aplicado a cualquier aseveración. Para contribuir usó un modelo teórico sumamente sencillo, que consistía en una máquina. Turing fue la primera herramienta teórica para explorar los límites de las aún inexistentes computadoras. Las implicaciones de Turing resultaron ser los orígenes de lo que hoy se conoce como teoría de la computación.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ruta_archivo = \"./turing.txt\"\n",
    "texto_original = cargar_texto(ruta_archivo)\n",
    "\n",
    "print_texto(\"\\nTexto original:\")\n",
    "print_texto(texto_original[:500] + \"...\\n\") \n",
    "\n",
    "resumen = resumir_texto(texto_original)\n",
    "\n",
    "print(\"Resumen:\")\n",
    "print_texto(resumen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
